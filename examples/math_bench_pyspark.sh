spark-submit \
  --archives env.zip#env \                                   # Distribute the virtual environment
  --conf "spark.pyspark.python=./env/bin/python" \           # Set Python executable for workers
  --conf "spark.pyspark.driver.python=./env/bin/python" \    # Set Python executable for driver
  --conf "spark.app.name=pdf2dataset" \                      # Set the application name
  --conf "spark.driver.memory=16G" \                         # Set driver memory
  --conf "spark.executor.memory=16G" \                       # Set memory per executor
  --conf "spark.executor.cores=16" \                         # Set number of cores per executor
  --conf "spark.dynamicAllocation.enabled=true" \            # Enable dynamic allocation
  --conf "spark.dynamicAllocation.minExecutors=4" \          # Minimum number of executors
  --conf "spark.dynamicAllocation.maxExecutors=64" \         # Maximum number of executors \
  submit_job.py \
  --processes_count=16 \
  --thread_count=32 \
  --url_list="s3://my-numina/CC-text5B-math" \
  --output_folder="s3://my-numina/bench-math" \
  --output_format="files" \
  --input_format="parquet" \
  --url_col="url" \
  --caption_col="alt" \
  --enable_wandb=True \
  --number_sample_per_shard=1000 \
  --distributor="pyspark" \
  --encode_format="pdf" \
  --retries=3
